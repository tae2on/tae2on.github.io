--- 
title: "AI 기반 자율주행 실내 배송 로봇 시스템"
date: 2023-07-08 15:16:45 +0900
math: true
categories: [Project]
tags: [Project, Autonomous Driving, Robot, PID, Motor]
---
---------- 	
> 인공지능을 탑재한 자율주행 실내 배송 로봇
{: .prompt-info } 

## **개요**
이 프로젝트는 제어시스템공학 연구실에서 캡스톤디자인 졸업작품 과제로 수행한 내용입니다. <br>
인공지능 기술을 활용하여 실내 자율주행 배송 로봇 시스템을 개발하는 것을 목표로 하였습니다. 로봇은 라이다 센서를 이용하여 실내 지도를 작성하며, PID 제어 기반 모터 구동으로 경로를 따라 이동합니다. 또한 CNN 기반 객체 인식으로 목표 인물을 판별하고, 음성 인식·출력 기능을 통해 사용자와 상호작용하며 배송 완료를 알립니다. 

### **주제선정**
최근 코로나19 팬데믹과 함께 비대면 및 스마트 물류 시스템에 대한 수요가 빠르게 증가하고 있습니다. 이에 본 연구실에서는 기존의 자율주행 자동차 기술을 확장하여, 실내 환경에서도 음성 인식, 라이다 기반 경로 탐색, 영상 인식, PID 제어를 결합한 배송 로봇을 개발하는 것을 연구 주제로 선정하였습니다. 단순한 주행 로봇을 넘어, 목표 인물과 장소를 직접 인식하고 결과를 사용자에게 전달할 수 있는 지능형 로봇을 구현함으로써 졸업작품으로서의 학문적·실용적 완성도를 높이고, 실제 응용 가능한 사례를 제시하는 데 의의를 두었습니다.

## **설계과정**
### **모터 제어**
로봇의 주행은 DC모터의 엔코더 기반으로 구현되었으며, 위치 추정은 Dead Reckoning 방식을 사용하였습니다. 엔코더를 통해 휠의 회전수를 측정하고 이를 거리와 각도로 환산하여 현재 위치를 계산하였습니다. 제어 알고리즘은 PID 제어기를 적용하여 목표 좌표와 실제 좌표 간의 오차를 줄이는 방식으로 동작하게 설계하였습니다. 

$$
u(t) = K_p e(t) + K_i \int e(t) \, dt + K_d \frac{de(t)}{dt}
$$

- P(Proportional): 현재 오차에 비례하여 제어값을 결정
- I(Integral) : 누적 오차를 보정해 장기적인 편차 제거
- D(Derivative) : 오차의 변화율을 고려해 응답을 안정화

이 제어기를 통해 직선 주행 시, 목표 지점까지의 거리 오차가 허용 범위 내에 들어오면 정지하고, 회전 시에는 목표 각도에 도달하면 정지하도록 설계하였습니다. 또한 전진, 후진과 좌·우 회전을 위한 제어 신호를 분리하여, 경로 계획 알고리즘이 지시하는 방향에 따라 모터가 적절히 동작할 수 있도록 구현하였습니다. 

### **라이다 센서**
로봇의 자율주행을 위해 라이다 센서를 활용하여 실내 환경을 인식하고 지도를 작성하였습니다. 라이다는 주변 레이저를 발사한 뒤 반사되어 돌아오는 시간을 측정하여 거리와 각도 정보를 획득하고 이를 통해 로봇 기준 360° 방향의 장애물 위치를 실시간으로 파악하였습니다. 획득한 거리 데이터는 SLAM 알고리즘에 적용되어, 로봇이 주행하면서 실내 지도를 작성하고 동시에 자신의 위치를 추정할 수 있도록 하였습니다. 이 과정에서 작성된 맵은 경로 계획 알고리즘과 연동되어, 로봇이 목적지로 이동하면서 장애물을 회피하고 안전한 경로를 선택할 수 있습니다. 

### **음성 인식**
로봇은 사용자의 명령을 음성 입력으로 받아 자율주행을 시작하거나 특정 동작을 수행할 수 있도록 설계하였습니다. 이를 위해 STT 기술을 적용하여 사용자의 음성을 텍스트 명령어로 변환하고, 반환된 명령은 로봇 제어 모듈로 전달됩니다. 또한 로봇은 배송 임무가 완료되면 TTS를 통해 결과를 음성으로 출력합니다. 

### **영상 인식**
로봇은 카메라를 통해 실내 환경과 사용자를 인식할 수 있도록 설계하였습니다. 영상 인식은 크게 특정 색상을 탐지하여 장소를 판별하는데 사용되는 컬러 인식과 배송 대상 인물을 식별하기 위해 CNN 기반 얼굴 인식 알고리즘 2개로 나뉩니다. 컬러인식의 경우, OpenCV 라이브러리를 이용하여 HSV 색 공간에서 색상 범위를 지정하고, 마스크 처리 후 객체의 위치를 추적하였습니다. 얼굴인식은 카메라 영상에서 얼굴 영역을 추출한 뒤, 학습된 모델과 비교하여 대상 인물 여부를 판별하게 설계하였습니다. 

## **산출물** 
알루미늄 프레임 기반으로 제작된 실내 자율주행 배송 로봇의 시제품입니다. 상단에는 라이다 센서를 장착하여 실내 환경을 인식하고, 내부에는 DC모터와 제어보드(Raspberry Pi, Jetson Nano), 배터리 전원부가 탑재되어 있습니다. 

![시제품](https://github.com/tae2on/tae2on.github.io/blob/main/assets/img/AIDriveBot%20%EC%8B%9C%EC%A0%9C%ED%92%88.png?raw=true)

### **모터 제어**
PID 제어 기반 Dead Reckoning을 적용하여 직선 주행 및 회전 동작을 실험하였다.

![모터제어](https://github.com/tae2on/tae2on.github.io/blob/main/assets/img/%EB%AA%A8%ED%84%B0%20%EC%8B%A4%ED%97%98.gif?raw=true)

## **실험 결과**
자율주행 배송 로봇은 여러 환경에서 단계적으로 성능 검증을 진행하였습니다. 먼저 모터 제어 실험에서는 PID 알고리즘을 적용한 주행이 개방 루프 방식에 비해 훨씬 안정적인 동작을 보였으며 직선 주행에서는 목표 지점 근처에서 ±5cm 이내의 오차로 정지하였으며, 회전 주행에서는 목표 각도와 실제 회전 각도의 오차가 평균 3° 이내로 수렴하는 것을 확인할 수 있었습니다. 라이다 기반 SLAM 실험에서는 로봇이 이동하면서 실내 환경의 2차원 지도를 정상적으로 작성하였고, 장애물이 존재하는 상황에서도 Potential Field 알고리즘을 통해 충돌하지 않고 목적지까지 도달할 수 있었습니다. 음성 인식 기능 역시 기본 명령어를 안정적으로 인식하였고, 배송이 완료된 후에도 TTS 기능을 통해 안내를 출력하여 사용자와의 상호작용을 원활하게 이루어질 수 있었습니다. 영상 인식 실험에서는 컬러 마커를 이용하여 장소를 식별할 수 있었으며, CNN 기반 얼굴 인식을 통해 대상 인물을 90%의 성공률로 판별할 수 있었습니다. 다만 조명 환경이나 카메라 각도 변화에 따라 인식 정확도가 다소 낮아지는 한계도 발견되었습니다. 

## **고찰**
이번 프로젝트를 통해 복잡한 시스템일수록 단계적인 검증 절차가 필수적이라는 것을 한번 더 깨달을 수 있었습니다. 모터 제어 실험 과정에서 한 번은 엔코더가 고장나면서 주행이 제대로 이루어지지 않는 문제가 발생하였는데, 이때 단계 검증 과정을 통해 원인을 빠르게 파악하여 문제를 해결할 수 있었습니다. 이 경험은 작은 하드웨어 오류도 전체 시스템 동작에 큰 영향을 미칠 수 있다는 사실을 느낄 수 있었으며, 사전 검증과 반복 실험의 중요성을 다시 확인할 수 있었습니다. 