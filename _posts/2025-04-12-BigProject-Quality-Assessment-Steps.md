--- 
title: "빅프로젝트 | 품질 평가 단계" 
date: 2025-04-12 20:46:45 +0900
achieved: 2025-01-12 19:48:27 +0900
math: true
categories: [Bootcamp, KT Aivle School]
tags: [Bootcamp, KT Aivle School, Big Project]
---
---------- 	
> KT 에이블스쿨 빅프로젝트 품질 평가 단계(1.27 ~ 2.07)에 대한 글입니다. 
{: .prompt-info } 

## **빅프로젝트 개요**
빅프로젝트는 기업의 실무 프로세스 절차와 방식을 경험(고객정의, 이슈 파악, 솔루션 제안 및 구현)하며 문제 해결 역량과 협업 능력을 키우는 실무형 프로젝트입니다. 이를 통해 AI/IT 기술을 활용한 디지털 혁신 솔루션을 제안하고 구현하는 과정이 포함됩니다. 

### **빅프로젝트 일정**

- 1 ~ 2주차: 과제 심의 단계
- 3 ~ 4주차: 타당성 검토 단계 
- 5 ~ 6주차: 품질 평가 단계
- 7주차: 완료 처리 단계 
- 8주차: 발표회 

## **선정된 주제**

**도서 내용을 웹툰화를 통한 광고 제작**

1. 도서 내용의 서문을 자연어 처리 모델을 통해 스크립트 형식으로 변형
2. 생성된 스크립트 내용을 통해 웹툰 형식의 이미지 생성
3. 완성된 웹툰 이미지를 광고 및 마케팅 자료로 활용하여 도서의 홍보 효과 극대화

## **팀원 소개**
진현(팀장), 이상화, 이성훈, 이현제, 정민규, 황태언

### **역할 분담**

- Web: 진현, 이성훈
- GenAI: 이현제, 정민규
- NLP: 이상화, 황태언

도서 내용을 웹툰화하기 위해서는 요약이 아닌 등장인물의 특징 및 시대적 배경, 스토리텔링 중심의 스크립트 형식으로 필요하다고 생각하였습니다. 원작의 분위기를 유지하면서 장면 간의 전환이 매끄럽게 이어지는 스토리 구성이 중요하다고 생각하여 해당 역할을 NLP 팀이 담당하였습니다. 

## **시나리오 모델**

### **이전 시도 및 문제점 요약**
- 1차 시도: 서문 전체(약 2만 자)를 한번에 입력
    - 모델의 최대 입력 길이(1024토큰) 한계로 처리 실패
- 2차 시도: 500자 단위로 분할하여 KoBART, KoT5, KoGPT2로 비교한 결과, 시나리오 형태로 구성이 잘되는 KoBART를 최종 모델로 선정
    - 문장 단위 분할이 매끄럽지 않아 일부 내용이 누락
    - 컷 간의 이야기 흐름이 부자연스러워 몰입도 저하

### **3차 시도**

- 입력 기준: 정규식을 통해 문장이 자연스럽게 끝나는 지점에서 분리
- 활용 모델: `kobart`
- 목표 출력: 30~40컷 분량의 웹툰용 장면 및 대사 구성

**결과**
- 텍스트 전처리
    - 텍스트 내에 한국어 외 한자 및 일본어 등 다른 외국어가 존재할 경우 제거
    - 문장이 자연스럽게 끝나는 온점(.), 느낌표(!), 물음표(?)에서 분리
    - 열린 따옴표 쌍이 있을 경우 무조건 닫힌 따옴표가 나온 후에 분리 
- 학습 결과
    - 일관된 시나리오 형태 유지 
    - 컷 간 자연스럽고 매끄러운 전개 완성

**예시 출력**

```
    {
        "location": " 생태연구소 산하 유전자 복원소A연구소 ",
        "caption": "아리가 추워하고 있고 산호가 아리에게 망고스틴을
        건네고 있다.",
        "dialogues":[
            {
            “speaker": "아리",
            “dialogue”: “추워. 추워서 못 살겠어.”
            },
            {
            “speaker”:””,
            “dialogue": ""
            }
        ]
    }
```

> 위와 같은 형태로 각 장면마다 배경, 설명, 등장인물의 대사까지 구조화된 시나리오를 생성하였습니다.

## **인물 특징 및 시대적 배경 추출 모델**
### **이전 시도**
- 1차 시도: 기존 NER 모델을 활용하여 등장인물의 이름, 시대적 배경 등 고유명사 추출
    - 고유명사를 정확하게 인식하지 못함

### **2차 시도**
- 접근 방식: 별도의 학습 없이 빠른 적용이 가능한 GPT API 활용
    - 프롬프트에 원하는 출력 형태(인물 특징 및 시대적 배경)를 명시
- 목표 출력: 인물의 특징 및 시대적 배경 

**문제점 및 한계**
- 결과의 일관성이 부족
    - 실행할 때마다 매번 인물 혹은 인물의 특징이 다르게 추출
    - 동일한 입력에 대한 결과가 매번 달라지는 현상 발생
 
**추가 고려사항** 
이미지 생성 모델은 인물의 성격보다는 외형적 특징에 더 큰 영향을 받음 

### **3차 시도**
- 접근 방식: 시나리오 모델에서 생성된 speaker(발화자) 정보를 먼저 추출하고 해당 발화자를 기반으로 외형 묘사 및 시대적 배경 정보를 추출 
- 목표 출력: 인물의 외형적 특징 및 시대적 배경 정보

**결과**
- 일관된 인물 확보
    - 같은 발화자에 대한 거의 일관된 외형 및 시대적 배경 정보를 수집 가능

**예시 출력**

```
    {
        "background": "현대 도시 생활, 클럽 문화, 사적 연애",
        "characters": [
            {
            "name": "지수",
            "appearance": "현대 도시,여성, 긴 머리,
            20대 후반, 날씬한 체격,정장"
            },
            {
            "name": "윤",
            "appearance": "현대 도시,남성, 짧은 머리,
            30대 초반, 키가 크고 단정한 외모,정장"
            },
            {
            "name": "종업원",
            "appearance": "남성, 중간 길이 머리, 40대,
            보통 체격"
            }
        ]
    }
```

> 위와 같은 형태로 등장인물의 외형 및 배경 정보가 구조화되어 출력되며, 캐릭터 디자인 및 장면 생성의 기반 데이터로 활용되었습니다.

## **고찰**
시나리오 모델을 만드면서 모델의 데이터 구조를 어떻게 구성하느냐에 따라 결과의 품질이 크게 달라질 수 있다는 점을 체감할 수 있었습니다. 또한, 인물 특징 및 시대적 배경 추출 모델을 직접 파인튜닝하고 싶었으나 프로젝트의 마감 일정에 쫓기다 보니 시간적인 제약으로 충분히 시도하지 못한 점이 아쉬움으로 남습니다. 그럼에도 불구하고 주어진 시간 내에 다양한 시도를 통해 문제를 해결해나가며 완성도 있는 결과물을 만드는 과정 자체가 값진 경험으로 왔던 것 같습니다. 